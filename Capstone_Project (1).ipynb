{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip -q capstone1.zip"
      ],
      "metadata": {
        "id": "bRu0_MhAWOaE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q capstone2.zip"
      ],
      "metadata": {
        "id": "Ys8wTjFCLeoL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "metadata": {
        "id": "Kqz2kCIyY3fT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretain Layer"
      ],
      "metadata": {
        "id": "Vs_6zOlCJApe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset untuk training\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='./DATASET/TRAIN',  # Path ke folder TRAIN\n",
        "    labels='inferred',                   # Label otomatis dari nama folder\n",
        "    label_mode='binary',                    # Label numerik (0 atau 1)\n",
        "    image_size=(120, 120),               # Ukuran gambar (ubah sesuai model Anda)\n",
        "    batch_size=128                        # Ukuran batch\n",
        ")\n",
        "\n",
        "# Dataset untuk testing\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='./DATASET/TEST',   # Path ke folder TEST\n",
        "    labels='inferred',                   # Label otomatis dari nama folder\n",
        "    label_mode='binary',                    # Label numerik (0 atau 1)\n",
        "    image_size=(120, 120),               # Ukuran gambar (ubah sesuai model Anda)\n",
        "    batch_size=128                       # Ukuran batch\n",
        ")\n",
        "\n",
        "# Dataset untuk training\n",
        "train_dataset2 = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='./DATASET3/TRAIN',  # Path ke folder TRAIN\n",
        "    labels='inferred',                   # Label otomatis dari nama folder\n",
        "    label_mode='binary',                    # Label numerik (0 atau 1)\n",
        "    image_size=(120, 120),               # Ukuran gambar (ubah sesuai model Anda)\n",
        "    batch_size=128                        # Ukuran batch\n",
        ")\n",
        "\n",
        "# Dataset untuk testing\n",
        "test_dataset2 = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='./DATASET3/TEST',   # Path ke folder TEST\n",
        "    labels='inferred',                   # Label otomatis dari nama folder\n",
        "    label_mode='binary',                    # Label numerik (0 atau 1)\n",
        "    image_size=(120, 120),               # Ukuran gambar (ubah sesuai model Anda)\n",
        "    batch_size=128                       # Ukuran batch\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIofBUwKY4yp",
        "outputId": "42ecc0bb-bef2-4b99-9c0c-01e8511dbf3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22564 files belonging to 2 classes.\n",
            "Found 2513 files belonging to 2 classes.\n",
            "Found 22564 files belonging to 2 classes.\n",
            "Found 2513 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.concatenate(train_dataset2)\n",
        "test_dataset = test_dataset.concatenate(test_dataset2)"
      ],
      "metadata": {
        "id": "GI0Z3GpSIFOc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize the datasets for training\n",
        "SHUFFLE_BUFFER_SIZE = 10000\n",
        "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = (train_dataset\n",
        "                       .cache()\n",
        "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
        "                       .prefetch(PREFETCH_BUFFER_SIZE)\n",
        "                       )\n",
        "\n",
        "test_dataset = (test_dataset\n",
        "                            .cache()\n",
        "                            .prefetch(PREFETCH_BUFFER_SIZE)\n",
        "                            )"
      ],
      "metadata": {
        "id": "Sro51yKDH66Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first batch of images and labels\n",
        "for images, labels in train_dataset.take(5):\n",
        "\texample_batch_images = images\n",
        "\texample_batch_labels = labels\n",
        "example_batch_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfElFMoNadNt",
        "outputId": "00d5e265-dd6f-4b6e-9653-ece4d7c388c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-17-8506159ca601>\", line 2, in <cell line: 2>\n",
            "    for images, labels in train_dataset.take(5):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 826, in __next__\n",
            "    return self._next_internal()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 776, in _next_internal\n",
            "    ret = gen_dataset_ops.iterator_get_next(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3081, in iterator_get_next\n",
            "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 826, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-8506159ca601>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the first batch of images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mexample_batch_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3080\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3082\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_model = tf.keras.Sequential([\n",
        "# Specify the input shape.\n",
        "    tf.keras.Input(shape=(120, 120, 3)),\n",
        "    # Add the augmentation layers\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2, fill_mode='nearest'),\n",
        "    tf.keras.layers.RandomTranslation(0.2,0.2, fill_mode='nearest'),\n",
        "    tf.keras.layers.RandomZoom(0.2, fill_mode='nearest')])"
      ],
      "metadata": {
        "id": "wmgPOwcdaheF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your model for augmentation\n",
        "data_augmentor = augmentation_model\n",
        "\n",
        "# Take a sample image\n",
        "sample_image = tf.keras.utils.array_to_img(example_batch_images[0])\n",
        "\n",
        "images = [sample_image]\n",
        "\n",
        "# Apply random augmentation 3 times\n",
        "for _ in range(3):\n",
        "\timage_aug = data_augmentor(tf.expand_dims(sample_image, axis=0))\n",
        "\timage_aug = tf.keras.utils.array_to_img(tf.squeeze(image_aug))\n",
        "\timages.append(image_aug)\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(14, 7))\n",
        "for ax, image, title in zip(axs, images, ['Original Image', 'Augmented 1', 'Augmented 2', 'Augmented 3']):\n",
        "    ax.imshow(image, cmap='gray')\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hXQogNS3cw0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(120, 120, 3)),\n",
        "    augmentation_model,\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "# Set the training parameters\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',  optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hhUeloBjc52x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\tmodel.evaluate(example_batch_images, example_batch_labels, verbose=False)\n",
        "except:\n",
        "\tprint(\"Your model is not compatible with the dataset you defined earlier. Check that the loss function, last layer and label_mode are compatible with one another.\")\n",
        "else:\n",
        "\tpredictions = model.predict(example_batch_images, verbose=False)\n",
        "\tprint(f\"predictions have shape: {predictions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtAZnbbZdH7k",
        "outputId": "1c7e2ec8-1d9c-4bff-c3c3-37c2abedb0d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your model is not compatible with the dataset you defined earlier. Check that the loss function, last layer and label_mode are compatible with one another.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED CLASS: EarlyStoppingCallback\n",
        "\n",
        "### START CODE HERE ###\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the correct function signature for on_epoch_end method\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # Check if the accuracy is greater or equal to 0.8 and validation accuracy is greater or equal to 0.8\n",
        "        if logs['accuracy'] >= 0.8 and logs['val_accuracy'] >= 0.85:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "            print(\"\\nReached 80% train accuracy and 80% validation accuracy, so cancelling training!\")\n",
        "\n",
        "### END CODE HERE ###"
      ],
      "metadata": {
        "id": "ROqxTGy0dNQN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model and save the training history\n",
        "# This may take up to 10-15 min so feel free to take a break! :P\n",
        "history = model.fit(\n",
        "\ttrain_dataset,\n",
        "\tepochs=10,\n",
        "\tvalidation_data=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "UMeanMXTda5N",
        "outputId": "10b5c1a7-29f5-4259-e56b-49f72536e97d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6efe642fcf09>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model and save the training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This may take up to 10-15 min so feel free to take a break! :P\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation accuracies\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "fig.suptitle('Training and validation accuracy')\n",
        "\n",
        "for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], [\"Accuracy\", \"Loss\"])):\n",
        "    ax[i].plot(epochs, data[0], 'r', label=\"Training \" + label)\n",
        "    ax[i].plot(epochs, data[1], 'b', label=\"Validation \" + label)\n",
        "    ax[i].legend()\n",
        "    ax[i].set_xlabel('epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zBAZeuJJdfc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Fungsi untuk memuat dan memproses gambar\n",
        "def load_and_preprocess_image(image_path, img_size=(120, 120)):\n",
        "    # Muat gambar\n",
        "    img = tf.keras.utils.load_img(image_path, target_size=img_size)  # Load gambar dan ubah ukurannya\n",
        "    # Konversi ke array\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    # Tambahkan dimensi batch\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Normalisasi (skala 0–1)\n",
        "    img_array = img_array / 255.0\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "cyk2Clj6ec0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path ke gambar baru\n",
        "image_path = 'botol.jpg'  # Ganti dengan path gambar Anda\n",
        "\n",
        "# Preproses gambar\n",
        "processed_image = load_and_preprocess_image(image_path)\n",
        "# Lakukan prediksi\n",
        "predictions = model(processed_image)\n",
        "predicted_class = np.argmax(predictions[0])  # Ambil indeks kelas dengan probabilitas tertinggi\n",
        "print(f\"Predicted Class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "sQJDczIDu2xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functional API"
      ],
      "metadata": {
        "id": "2NfZPtkeJHd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
        "## You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
        "class Block(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
        "        super(Block, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.repetitions = repetitions\n",
        "\n",
        "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
        "        for i in range(self.repetitions):\n",
        "\n",
        "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
        "            vars(self)[f'conv2D_{i}'] =  tf.keras.layers.Conv2D(\n",
        "                    filters=self.filters,\n",
        "                    kernel_size=self.kernel_size,\n",
        "                    activation=\"relu\",  # Assuming ReLU activation\n",
        "                    padding=\"same\"\n",
        "                )\n",
        "\n",
        "        # Define the max pool layer that will be added after the Conv2D blocks\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=pool_size, strides=strides)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # access the class's conv2D_0 layer\n",
        "        conv2D_0 = vars(self)[f'conv2D_0']\n",
        "\n",
        "        # Connect the conv2D_0 layer to inputs\n",
        "        x = conv2D_0(inputs)\n",
        "\n",
        "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
        "        for i in range(1, self.repetitions):\n",
        "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
        "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
        "\n",
        "            # Use the conv2D_i and connect it to the previous layer\n",
        "            x = conv2D_i(x)\n",
        "\n",
        "        # Finally, add the max_pool layer\n",
        "        max_pool = self.max_pool(x)\n",
        "\n",
        "        return max_pool"
      ],
      "metadata": {
        "id": "1Qqx4wIZvzd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
        "## You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
        "\n",
        "class MyVGG(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyVGG, self).__init__()\n",
        "\n",
        "        # Creating blocks of VGG with the following\n",
        "        # (filters, kernel_size, repetitions) configurations\n",
        "        self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\n",
        "        self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\n",
        "        self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\n",
        "        self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "        self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "\n",
        "        # Classification head\n",
        "        # Define a Flatten layer\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
        "        self.fc = tf.keras.layers.Dense(units=256, activation='relu')\n",
        "        # Finally add the softmax classifier using a Dense layer\n",
        "        self.classifier = tf.keras.layers.Dense(units=2, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Chain all the layers one after the other\n",
        "        x = self.block_a(inputs)\n",
        "        x = self.block_b(x)\n",
        "        x = self.block_c(x)\n",
        "        x = self.block_d(x)\n",
        "        x = self.block_e(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1pwCvATzQRtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For reference only. Please do not uncomment in Coursera Labs because it might cause the grader to time out.\n",
        "# You can upload your notebook to Colab instead if you want to try the code below.\n",
        "\n",
        "# Initialize VGG with the number of classes\n",
        "vgg = MyVGG(num_classes=2)\n",
        "\n",
        "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#\n",
        "# Define preprocessing function\n",
        "def preprocess(features):\n",
        "    # Resize and normalize\n",
        "    image = tf.image.resize(features['image'], (120, 120))\n",
        "    return tf.cast(image, tf.float32) / 255., features['label']\n",
        "\n",
        "\n",
        "# Train the custom VGG model\n",
        "history = vgg.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=5,\n",
        ")"
      ],
      "metadata": {
        "id": "Pf09-uf7QVQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model\n",
        "loss, accuracy = vgg.evaluate(test_dataset)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "w1fRCCjgQt6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path ke gambar baru\n",
        "image_path = 'botol.jpg'  # Ganti dengan path gambar Anda\n",
        "\n",
        "# Preproses gambar\n",
        "processed_image = load_and_preprocess_image(image_path)\n",
        "# Lakukan prediksi\n",
        "predictions = vgg.predict(processed_image)\n",
        "predicted_class = np.argmax(predictions[1])  # Ambil indeks kelas dengan probabilitas tertinggi\n",
        "print(f\"Predicted Class: {predicted_class}\")"
      ],
      "metadata": {
        "id": "8S-ratWKSU2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kaggle"
      ],
      "metadata": {
        "id": "VA5dgSW9J1pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "zfYyFcB-S7Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageFolder(root='./DATASET/TRAIN', transform=transforms)\n",
        "test_dataset = ImageFolder(root='./DATASET/TEST', transform=transforms)"
      ],
      "metadata": {
        "id": "k7aruHWyY914"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8*len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "hesvlrgDYnnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "len(train_loader), len(val_loader), len(test_loader)"
      ],
      "metadata": {
        "id": "AP3viRrGY5yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # first layer\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # second layer\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # third layer\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=29*29*16, out_features=120),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # fourth layer\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            nn.Linear(in_features=84, out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "UwzA7NqTZGxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()"
      ],
      "metadata": {
        "id": "sTo52kNpZWha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "dknVqCrYZaQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        # Move data to the appropriate device\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        train_loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_train_loss += train_loss.item() * images.size(0)  # Accumulate loss\n",
        "\n",
        "    # Average training loss for the epoch\n",
        "    epoch_train_loss /= len(train_loader.dataset)\n",
        "    training_loss.append(epoch_train_loss)\n",
        "    model.eval()\n",
        "    epoch_val_loss = 0.0\n",
        "    with torch.inference_mode():\n",
        "        for val_images, val_labels in val_loader:\n",
        "            # Move validation data to the appropriate device\n",
        "\n",
        "            val_outputs = model(val_images)\n",
        "            val_loss = loss_fn(val_outputs, val_labels)\n",
        "            epoch_val_loss += val_loss.item() * val_images.size(0)  # Accumulate loss\n",
        "\n",
        "    # Average validation loss for the epoch\n",
        "    epoch_val_loss /= len(val_loader.dataset)\n",
        "    validation_loss.append(epoch_val_loss)\n",
        "\n",
        "    # Print loss for the epoch\n",
        "    print(f\"Epoch: {epoch+1}/{epochs}, Training Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "LVdleMJVZi4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = []\n",
        "actual_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "        actual_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "7qfEAHNyZvto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# print precision\n",
        "\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "print(f\"Model Precision: {precision * 100:.2f}%\")\n",
        "\n",
        "# print recall\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "print(f\"Model Recall: {recall * 100:.2f}%\")\n",
        "\n",
        "# print f1 score\n",
        "\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "print(f\"Model F1 Score: {f1 * 100:.2f}%\")\n",
        "\n",
        "# print classification report\n",
        "\n",
        "print(classification_report(actual_labels, predicted_labels))\n",
        "# get confsion matrix and print actual labels\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "\n",
        "class_names = test_loader.dataset.classes\n",
        "# visualize confusion matruix using sns\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YYthv_ewc2CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubDRKxmOdFfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}